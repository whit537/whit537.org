title = "A Technological Agenda"
published = "2007-12-09T20:37:00.000-05:00"
updated = "2011-04-10T09:52:45.186-04:00"
^L
^L
{% extends "base.html" %}
{% block content %}
Per my last <a href="http://blag.whit537.org/2007/12/future.html">post</a>, I find <a href="http://en.wikipedia.org/wiki/Technological_singularity">singularity scenarios</a> pretty compelling. I'm not sure how much influence singularity-oriented think tanks such as the <a href="http://www.fhi.ox.ac.uk/">Future of Humanity Institute</a> (FHI) and the <a href="http://www.singinst.org/">Singularity Institute for Artificial Intelligence</a> (SIAI) have and will have, but it could be interesting to get involved in that scene. I would try to convince people of two things:<br /><ol><li>Humanity should slow the f*** down. Fix bugs before you add new features. Prioritize personal relationships and local community over progress in technology. Exercise patience and humility. There's nothing inherently wrong with AI, but if you're thinking big, what's the rush? Why the urgency?<br /><br /></li><li>We should nurture the Amish as our contingency plan. They won't do much good in the case of existential risk, but if and when catastrophic risk hits, the Amish are our best hope for keeping the flame alive.</li></ol>SIAI runs a few <a href="http://www.singinst.org/discussion/">mailing lists</a> and an <a href="http://www.singinst.org/summit2007/">autumn conference</a>. Not sure about FHI. But I mean, c'mon, talk about an uphill battle!<div class="blogger-post-footer"><img width='1' height='1' src='https://blogger.googleusercontent.com/tracker/36506138-1716063755058216234?l=blag.whit537.org' alt='' /></div>
{% end %}
