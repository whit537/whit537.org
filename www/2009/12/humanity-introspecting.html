title = "Humanity, introspecting"
published = "2009-12-03T15:23:00.009-05:00"
updated = "2011-04-10T09:52:44.952-04:00"
^L
^L
{% extends "blag.html" %}
{% block content %}
<div style="padding-bottom: 1em;"><i>Currently listening to: "</i><a href="http://www.lala.com/#song/432627047863025823"><i>Fifteen</i></a><i>," by Taylor Swift.</i></div><p>The music services (Lala, Last.fm, Pandora, etc.) provide related content by genre, but is anyone organizing music based on content? Because if you sort songs by content, there's really only, like, eight songs:</p><p></p><ul><li><b>romance</b> ("<a href="http://www.lala.com/#song/432627047863025823">Fifteen</a>," by Taylor Swift)</li><li><b>sex</b> ("<a href="http://www.youtube.com/watch?v=QubWKLQUrN0">3</a>," by Britney Spears)</li><li><b>anger</b> ("<a href="http://www.youtube.com/watch?v=pdgQlzbEtRI">Girls</a>", by Eminem)</li><li><b>humanism</b> ("<a href="http://www.youtube.com/watch?v=cQyGYdRqulQ">One Love</a>," by David Guetta)</li><li><b>drinking </b>("Whiskey in the Jar," <a href="http://www.youtube.com/watch?v=r5WgYoRCs2U">by the Pogues</a>)</li><li><b>politics</b> ("<a href="http://www.lala.com/#song/504684672194509639">Beds are Burning</a>," by Midnight Oil)</li><li><b>religion</b> ("<a href="http://www.lala.com/#song/432627043558820085">Vertigo</a>," by U2)</li><li><b>quirkiness</b> ("<a href="http://www.youtube.com/watch?v=fqz1ojIQTBk">Fat</a>," by Weird Al)</li></ul><p>You'd actually probably end up with a few more categories (nationalism? philosophy? musicianship?) but you get the idea. And here's the thing: we don't have to come up with the categories ourselves. We'll have the computers do it for us. The Netflix prize demonstrated that genres <a href="http://pragmatictheory.blogspot.com/2008/08/you-want-truth-you-cant-handle-truth.html">come out in the wash</a> when you have a large enough data set: check out this <a href="http://www2.research.att.com/~yifanhu/MovieMap/">automatically generated movie map</a>!</p><p>Each of the categories above represents a "moment," if you will, that each of us experiences personally to one degree or another. By analyzing the content of popular music, we could get an aggregate view of humanity's collective mental state. I think that would be a fascinating thing to have. We would look at how the content of music evolves over time; that would be humanity remembering what it used to feel like. We would subset by genre to look for empirical answers to assertions like "rap is angry;" that would be humanity, introspecting.</p><p>You could do something similar with movies, but pop songs would be better for at least two reasons. First, a pop song is more singular than a movie; the ratio of moments ("anger") to items (each song/movie)  is nearly one. Second, the volume of pop songs per year is higher; you have higher throughput.</p><p>So I'm thinking the initial data set would be date-stamped lyrics. Sooner or later you would want to bring the waveforms themselves into play. I suppose given waveforms you could do speech recognition to generate lyrics automatically, but there are lots of lyrics sites out there already. At the very least you want waveforms to help identify emphasis (lyrics would give you repetition). Perhaps you could skip natural language processing altogether and go straight to grouping based on the waveforms of the words of the songs rather than their character representations, but for me at least characters are going to be easier to work with than waveforms.</p><p>Where would you start?</p><div class="blogger-post-footer"><img width='1' height='1' src='https://blogger.googleusercontent.com/tracker/36506138-4536102193274422732?l=blag.whit537.org' alt='' /></div>
{% end %}
